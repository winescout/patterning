# Patterning CLI Tools

This repository contains CLI tools for analyzing E-mini futures trading videos. This `README.md` provides instructions for setting up your environment and using the initial spike for video ingestion.

## üöÄ Getting Started: Video Ingestion Spike

This spike is designed to help you validate your system's setup for video processing, including audio extraction with `ffmpeg` and transcription with the Video-Llama model.

### üìã Requirements for Use

Before running the spike, ensure you have the following software installed and configured:

1.  **Python 3.x and `uv` (or `pip`)**:
    *   It's recommended to use `uv` for dependency management. If you don't have it, install it:
        ```bash
        curl -LsSf https://astral.sh/uv/install.sh | sh
        ```
    *   Then, install project dependencies:
        ```bash
        uv pip install pytest pydub spacy moviepy==1.0.3
        ```

2.  **FFmpeg**:
    *   `ffmpeg` is essential for extracting audio from video files.
    *   **Installation Instructions:** Follow the official `ffmpeg` download and installation guide for your operating system: [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)
    *   **Verification:** After installation, open a new terminal and run:
        ```bash
        ffmpeg -version
        ```
        You should see version information. If not, ensure `ffmpeg` is in your system's PATH.

3.  **Whisper Model**:
    *   The Whisper model is used for transcribing audio content. It can be run on CPU, but GPU is recommended for faster transcription.
    *   **Installation:**
        ```bash
        uv pip install openai-whisper
        ```
    *   **Model Download:** The first time you run the spike, Whisper will automatically download the 'base' model. This may take some time depending on your internet connection.

4.  **spaCy Model**:
    *   `spaCy` is used for natural language processing, specifically for sentence boundary detection and basic keyword extraction in this spike.
    *   **Installation:**
        ```bash
        uv pip install spacy
        ```
    *   **Model Download:**
        ```bash
        python -m spacy download en_core_web_sm
        ```

### üõ†Ô∏è How to Use the Video Ingestion Spike

Once all requirements are met, you can run the end-to-end video ingestion spike:

1.  **Prepare a Test Video:** Have a small MP4 video file (e.g., 10-30 seconds) ready for testing. Note its full path.

2.  **Run the Spike Command:**
    ```bash
    uv run python src/main.py spike-ingest --video-path /path/to/your/test_video.mp4
    ```
    Replace `/path/to/your/test_video.mp4` with the actual path to your video file.

### üìä Expected Output

Upon successful execution, you should observe:

*   Console messages indicating the progress of audio extraction and Video-Llama transcription.
*   A new markdown file (e.g., `spike_output_xxxx.md`) created in your current working directory.

This markdown file will contain:
*   A clear title with the video's filename.
*   The full transcript generated by the Video-Llama model.
*   A structured list of identified topics, each with estimated start and end timestamps, and the corresponding text segment.

### ‚ö†Ô∏è Troubleshooting

*   **`ffmpeg not found` error:** Ensure `ffmpeg` is installed and its executable is in your system's PATH.
*   **Video-Llama loading/transcription errors:** Double-check the Video-Llama installation steps, model weight downloads, and any required environment variables. Ensure your system meets the hardware requirements (especially for GPU).
*   **`Video file not found` error:** Verify the `--video-path` argument is correct and the file exists.
*   **`spaCy model 'en_core_web_sm' not found`:** Run `python -m spacy download en_core_web_sm`.

If you encounter persistent issues, please refer to the `PRPs/video_ingestion_spike_e2e_prp.md` for more detailed technical context and troubleshooting steps.
